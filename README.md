# FrustumGaze

这是一个基于 MediaPipe 和 Unity 的视差同步与交互练手项目。旨在探索如何通过简单的摄像头捕捉，链接虚拟与现实世界，创造出具有“深度”和“交互性”的数字窗口。

> **说明**：本项目主要作为一个简单朴素的技术验证与学习项目（练手作），代码结构和实现方式可能较为初级，希望能起到抛砖引玉的作用，欢迎大家提出改进意见。

## 🌟 核心功能

*   **视差同步 (Frustum Culling/Gaze)**: 通过实时追踪用户的人脸和眼睛位置，计算视锥体，模拟从用户视角看过去的透视效果，产生“虚拟窗口”的视觉效果。
*   **多模态追踪**:
    *   **人脸与虹膜**: 捕捉用户头部姿态和注视点。
    *   **手部追踪**: 识别手部关键点，支持简单的手势交互。
*   **性能优化**: 采用多进程架构，将繁重的视觉计算、手部追踪分离到独立进程，通过共享内存通信，保证主渲染线程的流畅性。
*   **数据可视化**: 实时显示 FPS、丢包率以及追踪骨架的可视化反馈。
*   **3D 人物眼动追踪**: 在unity中实现3D人物紧盯用户与简单眨眼效果。*

## 📂 目录结构

```text
FrustumGaze/
├── config/                 # 配置文件
│   ├── cameras.json        # 摄像头参数配置
│   ├── settings.py         # 全局设置
│   └── user_prefs.json     # 用户偏好
├── modules/                # 核心功能模块
│   ├── camera.py           # 摄像头输入处理
│   ├── network.py          # 网络通信
│   ├── shared_mem.py       # 进程间共享内存管理
│   └── visualizer.py       # OpenCV 可视化绘制
├── trackers/               # 视觉追踪逻辑
│   ├── face_mesh.py        # 人脸与虹膜追踪进程
│   ├── hand_tracker.py     # 手部追踪进程
│   └── eye_tracker.py      # 眼动追踪逻辑
├── src/                    # Unity 客户端脚本 (C#)
│   ├── Camera/             # 虚拟相机控制
│   └── Character/          # 角色眼动控制
├── utils/                  # 通用工具函数
├── face_landmarker.task    # MediaPipe 模型文件
├── hand_landmarker.task    # MediaPipe 模型文件
└── main.py                 # 程序主入口
```

## 🚀 应用前景

虽然目前是一个基础 Demo，但此类技术在以下领域有广阔潜力：

*   **视觉小说**: 利用视差同步技术，为视觉小说添加“深度”和“交互性”，提升游戏体验。
*   **移动设备**: 调用加速度传感器与陀螺仪，统一虚拟与现实的坐标尺度，通过高斯泼溅等技术彻底统一虚拟与现实。
*   **虚拟窗口**: 将普通显示器变为具有深度的“窗户”，展示 3D 场景或全景视频。
*   **无接触交互**: 在公共展示屏中，通过手势和视线控制界面。
*   **VTuber/Avatar 驱动**: 低成本实现面部和手部的动作捕捉。
*   **增强现实 (AR) 体验**: 无需佩戴头显，仅通过屏幕实现裸眼 AR 效果。

## 📝 待实现功能 / 改进计划

*   [ ] **更复杂的交互**: 添加基于手势的点击、拖拽等具体交互逻辑。
*   [ ] **Unity 端完善**: 完善 Unity 端的接收与渲染逻辑，使其更加即插即用。
*   [ ] **多人支持**: 扩展人脸识别与用户数据库以支持多用户视线分析。

## 🛠️ 运行环境

*   Python 3.8+
*   OpenCV
*   MediaPipe
*   NumPy
*   Unity 2020+ 用于 3D 渲染端

---
*本项目仅供学习交流使用。*
